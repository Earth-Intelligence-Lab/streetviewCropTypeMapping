{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install tqdm"
      ],
      "metadata": {
        "id": "FQaxwZtSCcRn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhlciixJCdlW",
        "outputId": "5698e862-a475-4c2e-89f8-a85844e90bb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWZBGOIC_EDS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from transformers import ViTForImageClassification\n",
        "from scipy import stats\n",
        "\n",
        "\n",
        "\n",
        "label_to_int = {'cassava': 0, 'maize': 1, 'other': 2, 'rice': 3, 'sugarcane': 4, }\n",
        "\n",
        "class CustomImageDataset1(Dataset):\n",
        "    def __init__(self, images, labels, transforms=None, samples_per_class=None):\n",
        "        self.images = images\n",
        "        self.labels = [label_to_int[label] for label in labels]\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.images[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Remove top 30% of the image\n",
        "        width, height = image.size\n",
        "        image = image.crop((0, height * 0.3, width, height))\n",
        "\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, images, labels, transforms=None, sampling_factors=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "        self.sampling_factors = sampling_factors if sampling_factors is not None else {label: 1 for label in set(labels)}\n",
        "\n",
        "    def __len__(self):\n",
        "        # Calculate total length considering sampling factors\n",
        "        total_length = 0\n",
        "        for label in self.labels:\n",
        "            total_length += self.sampling_factors[label]\n",
        "        return total_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Find the actual image index based on the sampling factor\n",
        "        actual_idx = idx\n",
        "        for i, label in enumerate(self.labels):\n",
        "            if actual_idx < self.sampling_factors[label]:\n",
        "                break\n",
        "            actual_idx -= self.sampling_factors[label]\n",
        "\n",
        "\n",
        "        image = Image.open(self.images[i])\n",
        "        label = self.labels[i]\n",
        "\n",
        "        # Remove top 30% of the image\n",
        "        width, height = image.size\n",
        "        image = image.crop((0, height * 0.3, width, height))\n",
        "\n",
        "        # Process image\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        return image, label_to_int[label]\n",
        "\n",
        "def load_images(folder_path):\n",
        "    print(\"Loading images...\")\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    for class_folder in os.listdir(folder_path):\n",
        "        class_path = os.path.join(folder_path, class_folder)\n",
        "        for img_file in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, img_file)\n",
        "            images.append(img_path)\n",
        "            labels.append(class_folder)\n",
        "    print(\"Total images loaded:\", len(images))\n",
        "    return images, labels\n",
        "\n",
        "def split_dataset(images, labels, train_ratio=0.6, val_ratio=0.2):\n",
        "    # Split dataset into train, validation, and test\n",
        "    print(\"Splitting dataset...\")\n",
        "    dataset = list(zip(images, labels))\n",
        "    random.shuffle(dataset)\n",
        "    train_size = int(len(dataset) * train_ratio)\n",
        "    val_size = int(len(dataset) * val_ratio)\n",
        "    train_set = dataset[:train_size]\n",
        "    val_set = dataset[train_size:train_size + val_size]\n",
        "    test_set = dataset[train_size + val_size:]\n",
        "    print(f\"Dataset split into {len(train_set)} training, {len(val_set)} validation, and {len(test_set)} test images.\")\n",
        "    return train_set, val_set, test_set\n",
        "\n",
        "def count_class_distribution(dataset):\n",
        "    class_counts = {}\n",
        "    for _, label in dataset:\n",
        "        class_counts[label] = class_counts.get(label, 0) + 1\n",
        "    return class_counts\n",
        "\n",
        "def calculate_sampling_factors(train_set):\n",
        "    label_counts = Counter(label for _, label in train_set)\n",
        "    min_samples = min(label_counts.values())\n",
        "\n",
        "    # Calculate sampling factor for each class\n",
        "    sampling_factors = {label: round(min_samples / count) for label, count in label_counts.items()}\n",
        "    return sampling_factors\n",
        "\n",
        "def create_dataloaders(train_set, val_set, test_set, sampling_factors, batch_size):\n",
        "    # Define transformations\n",
        "    print(\"Creating dataloaders...\")\n",
        "\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.RandomCrop(224),  # Specify size\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    val_test_transforms = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    train_dataset = CustomImageDataset([i[0] for i in train_set], [i[1] for i in train_set], transforms=train_transforms, sampling_factors=sampling_factors)\n",
        "    val_dataset = CustomImageDataset([i[0] for i in val_set], [i[1] for i in val_set], transforms=val_test_transforms)\n",
        "    test_dataset = CustomImageDataset([i[0] for i in test_set], [i[1] for i in test_set], transforms=val_test_transforms)\n",
        "    # print('Dataset', train_dataset[0])\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    print(\"Dataloaders created.\")\n",
        "    print(len(train_loader), len(val_loader), len(test_loader))\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "def calculate_samples_per_class(class_distribution):\n",
        "    min_count = min(class_distribution.values())\n",
        "    samples_per_class = {label_to_int[cls]: min_count // count for cls, count in class_distribution.items()}\n",
        "    return samples_per_class\n",
        "\n",
        "\n",
        "\n",
        "def load_data(folder1):\n",
        "    images, labels = load_images(folder1)\n",
        "    train_set, val_set, test_set = split_dataset(images, labels)\n",
        "\n",
        "    # Print class distribution\n",
        "    train_class_distribution = count_class_distribution(train_set)\n",
        "    val_class_distribution = count_class_distribution(val_set)\n",
        "    test_class_distribution = count_class_distribution(test_set)\n",
        "\n",
        "    print(\"Training set class distribution:\", train_class_distribution)\n",
        "    print(\"Validation set class distribution:\", val_class_distribution)\n",
        "    print(\"Test set class distribution:\", test_class_distribution)\n",
        "\n",
        "    # sampling_factors = calculate_sampling_factors(train_set)\n",
        "    sampling_factors = {'rice': 1, 'other': 2, 'sugarcane': 6, 'cassava': 12, 'maize': 10}\n",
        "    print('Sampling factors: ', sampling_factors)\n",
        "    train_loader, val_loader, test_loader = create_dataloaders(train_set, val_set, test_set, sampling_factors, batch_size=8)\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_patches(image, patch_size, stride):\n",
        "    patches = []\n",
        "    c, height, width = image.size()\n",
        "\n",
        "    for y in range(0, height - patch_size[1] + 1, stride):\n",
        "        for x in range(0, width - patch_size[0] + 1, stride):\n",
        "            patch = image[:, y:y + patch_size[1], x:x + patch_size[0]]\n",
        "            patches.append(patch)\n",
        "\n",
        "    return patches\n",
        "\n",
        "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
        "    for images, labels in progress_bar:\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        #For ViT\n",
        "        logits = outputs.logits  # Extract the logits\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics\n",
        "        # _, predicted = torch.max(outputs, 1)\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        progress_bar.set_postfix(loss=loss.item(), accuracy=correct/len(labels))\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_correct += correct\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "        # For F1 score calculation\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    accuracy = total_correct / total_samples\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    per_class_f1 = f1_score(all_labels, all_preds, average=None)\n",
        "\n",
        "    return avg_loss, accuracy, f1, per_class_f1\n",
        "\n",
        "\n",
        "\n",
        "def validate_or_test(model, loader, criterion, device, patch_size, stride, desc='Val'):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_samples = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    progress_bar = tqdm(loader, desc=desc, leave=False)\n",
        "    with torch.no_grad():\n",
        "        for images, labels in progress_bar:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            batch_preds = []\n",
        "\n",
        "            for image in images:\n",
        "                # # Apply sliding window approach\n",
        "                # patches = extract_patches(image, patch_size, stride)\n",
        "                # patches = torch.stack(patches).to(device)\n",
        "\n",
        "                # # Aggregate predictions for each patch\n",
        "                # patch_outputs = model(patches)\n",
        "                # logits = patch_outputs.logits  # Extract the logits\n",
        "                # patch_predictions = torch.mean(logits, dim=0)\n",
        "                # patch_predictions = torch.mean(patch_outputs, dim=0)\n",
        "                # batch_preds.append(patch_predictions)\n",
        "\n",
        "                # Calculate the mode of the patch predictions\n",
        "\n",
        "                patches = extract_patches(image, patch_size, stride)\n",
        "                patches = torch.stack(patches).to(device)\n",
        "\n",
        "                # Aggregate predictions for each patch\n",
        "                patch_outputs = model(patches)\n",
        "                logits = patch_outputs.logits  # Extract the logits\n",
        "\n",
        "                # Calculate mode for each patch prediction\n",
        "                modes, _ = torch.mode(logits, dim=0)\n",
        "                batch_preds.append(modes)\n",
        "\n",
        "            print(batch_preds)\n",
        "            batch_preds = torch.stack(batch_preds)\n",
        "            loss = criterion(batch_preds, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(batch_preds, 1)\n",
        "            total_samples += labels.size(0)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "            # Update progress bar\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    per_class_f1 = f1_score(all_labels, all_preds, average=None)\n",
        "\n",
        "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "    conf_matrix_percentage = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(conf_matrix_percentage, annot=True, fmt='g', cmap='Blues')\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "    return avg_loss, accuracy, f1, per_class_f1\n",
        "\n",
        "def train_and_evaluate(model, train_loader, val_loader, test_loader, model_name, num_epochs=5, patch_size=(224, 224), stride=30):\n",
        "    # Criterion, Optimizer, and Scheduler\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "    global best_val_f1\n",
        "    global best_model_weights\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_accuracy, train_f1, train_f1_per_class = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}, F1 Score: {train_f1:.4f}')\n",
        "        print(f'Train F1 Score Per Class ', train_f1_per_class)\n",
        "\n",
        "        val_loss, val_accuracy, val_f1, val_f1_per_class = validate_or_test(model, val_loader, criterion, device, patch_size, stride, desc='Val')\n",
        "        print(f'Epoch {epoch+1}, Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, F1 Score: {val_f1:.4f}')\n",
        "        print(f'Val F1 Score Per Class ', val_f1_per_class)\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            best_model_weights = model.state_dict()  # Save the best model weights\n",
        "\n",
        "        # Save intermediate model weights\n",
        "        torch.save(model.state_dict(), imagesRoot+f'{model_name}_epoch_{epoch}.pth')\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "    test_loss, test_accuracy, test_f1, test_f1_per_class = validate_or_test(model, test_loader, criterion, device, patch_size, stride, desc='Test')\n",
        "    print(f'Test Loss: {test_loss:.3f}, Accuracy: {test_accuracy:.3f}, F1 Score: {test_f1:.3f}, F1 Score Per Class [{test_f1_per_class[0]:.3f}')\n",
        "    print(f'Test F1 Score Per Class ', test_f1_per_class)\n",
        "\n",
        "    # After training is complete, load the best model weights\n",
        "    model.load_state_dict(best_model_weights)\n",
        "\n",
        "    # Save the best model weights\n",
        "    torch.save(model.state_dict(), imagesRoot+f'{model_name}.pth')\n",
        "    return model"
      ],
      "metadata": {
        "id": "2Iz78yn6_S65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the main function with the path to folder1\n",
        "imagesRoot = '/content/drive/MyDrive/GSV-CropType-Thailand/images/'\n",
        "\n",
        "path_to_images = imagesRoot + 'validationByClassOther1'\n",
        "train_loader, val_loader, test_loader = load_data(path_to_images)\n",
        "\n",
        "def load_pretrained_vit(num_labels):\n",
        "    model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=num_labels)\n",
        "    return model\n",
        "\n",
        "num_classes = 5  # Adjust as per your dataset\n",
        "num_epochs = 20\n",
        "# Load the pretrained ResNet-50 model\n",
        "# model = models.resnet50(pretrained=True)\n",
        "vit_model = load_pretrained_vit(num_labels=num_classes)\n",
        "\n",
        "# model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "# Initialize best F1 score for validation\n",
        "\n",
        "best_val_f1 = 0.0\n",
        "best_model_weights = None\n",
        "model_name = 'ViT1-Thailand-4cropsOther-lr2e-4-ep10'\n",
        "trained_model = train_and_evaluate(vit_model, train_loader, val_loader, test_loader, model_name, num_epochs)"
      ],
      "metadata": {
        "id": "QsA9rp76_V9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(trained_model.parameters(), lr=2e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "trained_model.to(device)\n",
        "patch_size=(224, 224)\n",
        "stride=30\n",
        "test_loss, test_accuracy, test_f1, test_f1_per_class = validate_or_test(trained_model, test_loader, criterion, device, patch_size, stride, desc='Test')\n",
        "print(f'Test Loss: {test_loss:.3f}, Accuracy: {test_accuracy:.3f}, F1 Score: {test_f1:.3f}, F1 Score Per Class [{test_f1_per_class[0]:.3f}')\n",
        "print(f'Test F1 Score Per Class ', test_f1_per_class)"
      ],
      "metadata": {
        "id": "i0CX1RLOtcYU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}